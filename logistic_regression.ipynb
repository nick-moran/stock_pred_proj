{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>dir</th>\n",
       "      <th>dtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>think.invest.appl.alibaba.netflix.nvidia.tesla...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-02 09:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>store.jam.california.start.recreat.pot.sale.as...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>smart.lock.compani.otto.suspend.oper.fail.acqu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-02 07:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>isnt.microsoft.nasdaqmsft.year.ago.compani.mad...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>paul.r.la.monica.lamonicabuzz.januari.et.stock...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-02 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59097</th>\n",
       "      <td>59097</td>\n",
       "      <td>follow.stock.news.edit.follow.benjamin.rain.ed...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-02-01 19:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59098</th>\n",
       "      <td>59098</td>\n",
       "      <td>post.hayley.millar.appl.inc.nasdaqaapl.–.equit...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-02-01 18:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59099</th>\n",
       "      <td>59099</td>\n",
       "      <td>amazon.q.earn.breakdown.investor.worri.slow.gr...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-02-01 19:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59100</th>\n",
       "      <td>59100</td>\n",
       "      <td>post.hayley.millar.appl.nasdaqaapl.‘.stock.“.n...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-02-01 18:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59101</th>\n",
       "      <td>59101</td>\n",
       "      <td>start.post.micron.technolog.nasdaq.mu.vs.ume.u...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-02-01 18:49:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  dir  \\\n",
       "0               0  think.invest.appl.alibaba.netflix.nvidia.tesla...  1.0   \n",
       "1               1  store.jam.california.start.recreat.pot.sale.as...  1.0   \n",
       "2               2  smart.lock.compani.otto.suspend.oper.fail.acqu...  1.0   \n",
       "3               3  isnt.microsoft.nasdaqmsft.year.ago.compani.mad...  1.0   \n",
       "4               4  paul.r.la.monica.lamonicabuzz.januari.et.stock...  1.0   \n",
       "...           ...                                                ...  ...   \n",
       "59097       59097  follow.stock.news.edit.follow.benjamin.rain.ed... -1.0   \n",
       "59098       59098  post.hayley.millar.appl.inc.nasdaqaapl.–.equit... -1.0   \n",
       "59099       59099  amazon.q.earn.breakdown.investor.worri.slow.gr... -1.0   \n",
       "59100       59100  post.hayley.millar.appl.nasdaqaapl.‘.stock.“.n... -1.0   \n",
       "59101       59101  start.post.micron.technolog.nasdaq.mu.vs.ume.u... -1.0   \n",
       "\n",
       "                     dtime  \n",
       "0      2018-01-02 09:31:00  \n",
       "1      2018-01-02 00:00:00  \n",
       "2      2018-01-02 07:49:00  \n",
       "3      2018-01-02 00:00:00  \n",
       "4      2018-01-02 11:30:00  \n",
       "...                    ...  \n",
       "59097  2019-02-01 19:02:00  \n",
       "59098  2019-02-01 18:56:00  \n",
       "59099  2019-02-01 19:02:00  \n",
       "59100  2019-02-01 18:56:00  \n",
       "59101  2019-02-01 18:49:00  \n",
       "\n",
       "[59102 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./log_datasets/hourly_apple_alt.csv')\n",
    "ds = ds.dropna()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>kayla.tausch.nightli.busi.report.correspond.tw...</td>\n",
       "      <td>../news/2018_08_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>edgewood.manag.llc.lower.stake.appl.inc.nasdaq...</td>\n",
       "      <td>../news/2018_08_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>09:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>dow.jump.point.nasdaq.hit.presid.trump.announc...</td>\n",
       "      <td>../news/2018_08_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>19:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>south.korea.market.may.give.support.point.pm.e...</td>\n",
       "      <td>../news/2018_08_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>23:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>tim.cook.app.justin.sullivangetti.imag.might.s...</td>\n",
       "      <td>../news/2018_08_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64875</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>googl.hardwar.ambit.start.pay.evan.niu.cfa.mot...</td>\n",
       "      <td>../news/2018_12_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>00:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64876</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-12-13</td>\n",
       "      <td>etf.preview.etf.futur.point.higher.street.dige...</td>\n",
       "      <td>../news/2018_12_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>14:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64877</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>oneday.break.stock.market.continu.drop.thursda...</td>\n",
       "      <td>../news/2018_12_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64878</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>laurel.wealth.advisor.inc.lift.posit.appl.inc....</td>\n",
       "      <td>../news/2018_12_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>14:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64879</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>number.us.stock.futur.lower.morn.continu.eros....</td>\n",
       "      <td>../news/2018_12_d157b48c57be246ec7dd80e7af4388...</td>\n",
       "      <td>18:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64880 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company        date                                               text  \\\n",
       "0        aapl  2018-08-13  kayla.tausch.nightli.busi.report.correspond.tw...   \n",
       "1        aapl  2018-08-31  edgewood.manag.llc.lower.stake.appl.inc.nasdaq...   \n",
       "2        aapl  2018-08-27  dow.jump.point.nasdaq.hit.presid.trump.announc...   \n",
       "3        aapl  2018-08-01  south.korea.market.may.give.support.point.pm.e...   \n",
       "4        aapl  2018-08-19  tim.cook.app.justin.sullivangetti.imag.might.s...   \n",
       "...       ...         ...                                                ...   \n",
       "64875    aapl  2018-12-27  googl.hardwar.ambit.start.pay.evan.niu.cfa.mot...   \n",
       "64876    aapl  2018-12-13  etf.preview.etf.futur.point.higher.street.dige...   \n",
       "64877    aapl  2018-12-06  oneday.break.stock.market.continu.drop.thursda...   \n",
       "64878    aapl  2018-12-14  laurel.wealth.advisor.inc.lift.posit.appl.inc....   \n",
       "64879    aapl  2018-12-04  number.us.stock.futur.lower.morn.continu.eros....   \n",
       "\n",
       "                                                    file      time  \n",
       "0      ../news/2018_08_d157b48c57be246ec7dd80e7af4388...  00:00:00  \n",
       "1      ../news/2018_08_d157b48c57be246ec7dd80e7af4388...  09:13:00  \n",
       "2      ../news/2018_08_d157b48c57be246ec7dd80e7af4388...  19:27:00  \n",
       "3      ../news/2018_08_d157b48c57be246ec7dd80e7af4388...  23:01:00  \n",
       "4      ../news/2018_08_d157b48c57be246ec7dd80e7af4388...  20:00:00  \n",
       "...                                                  ...       ...  \n",
       "64875  ../news/2018_12_d157b48c57be246ec7dd80e7af4388...  00:23:00  \n",
       "64876  ../news/2018_12_d157b48c57be246ec7dd80e7af4388...  14:46:00  \n",
       "64877  ../news/2018_12_d157b48c57be246ec7dd80e7af4388...  00:00:00  \n",
       "64878  ../news/2018_12_d157b48c57be246ec7dd80e7af4388...  14:44:00  \n",
       "64879  ../news/2018_12_d157b48c57be246ec7dd80e7af4388...  18:00:00  \n",
       "\n",
       "[64880 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = pd.read_csv('./datasets/news_data_filtered_unique.csv')\n",
    "news_data = news_data.dropna()\n",
    "news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['text'] = news_data['text'].apply(lambda x: x.replace(\".\", \" \"))\n",
    "ds['text'] = ds['text'].apply(lambda x: x.replace(\".\", \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"(apple)|(aapl)|(appl)\")\n",
    "mask_text = ds['text'].apply(lambda x: bool(r.match(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5694, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds[mask_text]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer( max_features\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m vectorizer\u001b[39m.\u001b[39;49mfit(news_data[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m features \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mtransform(ds[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/st/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_for_unused_params()\n\u001b[1;32m   2085\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2086\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[1;32m   2087\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[1;32m   2088\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[1;32m   2089\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[1;32m   2090\u001b[0m )\n\u001b[0;32m-> 2091\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   2092\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m   2093\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/st/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1374\u001b[0m             )\n\u001b[1;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/st/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1264\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1263\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1264\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1265\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/miniconda3/envs/st/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/miniconda3/envs/st/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[0;32m---> 69\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer( max_features=16000)\n",
    "vectorizer.fit(news_data['text'])\n",
    "features = vectorizer.transform(ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(news_data['text'])\n",
    "features = vectorizer.transform(ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bin = CountVectorizer(binary=True, max_features=16000)\n",
    "vectorizer_bin.fit(news_data['text'])\n",
    "features_bin = vectorizer_bin.transform(ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ds['dir'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test = chi2(features,labels)\n",
    "mask = chi2_test[1] <= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5694, 2159)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_features = features[:,mask]\n",
    "chi2_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train, f_test, y_train, y_test = train_test_split(chi2_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', solver='liblinear').fit(f_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6619841966637401"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(f_test,y_test)\n",
    "#0.6619841966637401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5513608428446005\n"
     ]
    }
   ],
   "source": [
    "just_up = np.ones(y_test.shape)\n",
    "\n",
    "correct = sum(just_up == y_test)\n",
    "\n",
    "print(correct/len(just_up))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_ds = pd.read_csv('./log_datasets/AMAZON_text_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5876726886291179"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vectorizer.transform(amazon_ds['text'])\n",
    "labels = amazon_ds['dir'].to_numpy()\n",
    "f_train, f_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(penalty='l1', solver='liblinear').fit(f_train, y_train)\n",
    "clf.score(f_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(f_train.toarray(),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.485513608428446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(f_test.toarray(), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
